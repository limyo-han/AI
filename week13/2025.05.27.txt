RNN(recurrent neural network) - 과거의 상태를 고려

먼저 순환 데이터로 만든다.

윈도우의 크기 -> 이전 상태를 얼마나 반영할 것인가

p425
히든 상태 - 이전까지 입력된 정보들을 요약해 저장하는 메모리
새로운 은닉 상태 함수 

출력 벡터 -> CNN은 히든상태가 없다. 그러나 RNN은 히든상태가 있다.

은닉 상태 = tanh()어떤 것에 가중치를 줄 것인가

일대일 부분은 시험문제x

시간에 따른 역전파, BPTT
Backpropagation Through Time


RNN의 큰 문제
Sequential 모델에서 gradient vanishing problem 발생
-> LSTM 사용, Long Short-Term Memory

셀 상태를 나타내는 c가 추가됨, 장기 기억
gate -> long term과 short term 중에 어떤 정보를 선택할 것인가

**LSTM 유닛은 셀, 입력 게이트, 출력 게이트, 삭제 게이트로 구성
입력 게이트 -> 무엇을 셀에 저장할 것인가
출력 게이트 -> 현재 셀 상태를 기반으로 무엇을 출력할 것인가
삭제 게이트 -> 무엇을 셀에서 삭제할 것인가

연산이 너무 복잡해져서 보완하기 위해 GRU가 나옴



